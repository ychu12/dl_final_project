{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1714078756087,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"bHwsJ_pM7r1l","outputId":"f7bf6840-d468-47aa-e711-2a942242d675"},"outputs":[],"source":["# Helpfull code from https://www.kaggle.com/code/abhijitsingh001/predicting-gender-of-images/notebook\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import warnings\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,BatchNormalization\n","from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\n","from keras.optimizers import SGD,RMSprop\n","from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n","\n","from keras.models import Sequential\n","warnings.filterwarnings('ignore')\n","\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","from keras.layers import Dropout"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":109,"status":"ok","timestamp":1714078759312,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"aOahQ-FONXZj"},"outputs":[],"source":["# Converting the pixel data\n","def value_to_image(pixels):\n","    pixels = np.array(pixels.split(),'float64')\n","    pixels = np.reshape(pixels,(48,48))\n","    pixels = pixels / 255.0\n","    return pixels"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":111,"status":"ok","timestamp":1714078760800,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"2niVXpR3eJap"},"outputs":[],"source":["def categorical_accuracies(y_true, y_pred):\n","  # sanity check\n","  if len(y_true) != len(y_pred):\n","    print(\"y_true and y_pred are of different lengths\")\n","    return\n","\n","  correctness_tracker = {0:0, 1:0,2:0,3:0,4:0}\n","  sum_tracker = {0:0, 1:0,2:0,3:0,4:0}\n","  for i in range(0,len(y_true)):\n","    sum_tracker[y_true[i]] +=1\n","    if y_true[i] == y_pred[i]:\n","      correctness_tracker[y_true[i]] += 1\n","\n","  accuracy = {}\n","  for key in range(0,5):\n","    accuracy[key] = correctness_tracker[key] / sum_tracker[key] if sum_tracker[key] >0 else 0\n","  return accuracy\n","\n","def count_unique_values(array):\n","  counter = {0:0, 1:0,2:0,3:0,4:0}\n","  for element in array:\n","    counter[element] +=1\n","\n","  return counter"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1714078988868,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"y7JxTVYYQ_xE"},"outputs":[],"source":["'''\n","Data: a dictionary of training and testing\n","  Training: a pandas table of the original dataset\n","  Testing: a pandas table of the original dataset\n","'''\n","\n","# Changing dimensions of the data\n","def change_image_dimension(data):\n","    data = np.reshape(data.to_list(),(len(data),48,48,1))\n","    return data\n","\n","def make_model(data):\n","    training = data[\"training\"]\n","    testing = data['testing']\n","    title = data['title']\n","    train_img = training['pixels'].apply(value_to_image)\n","    test_img = testing['pixels'].apply(value_to_image)\n","\n","    train_cancer = training['cancer'] # 1 = there is a tumor, 0 = no tumor\n","    test_cancer = testing['cancer']\n","\n","    train_img = change_image_dimension(train_img)\n","    test_img = change_image_dimension(test_img)\n","\n","    train_img = train_img/255.0\n","    test_img = test_img/255.0\n","\n","    # CNN\n","    model=Sequential()\n","    model.add(Conv2D(256,(3,3),activation='relu',padding='same',input_shape=(48,48,1)))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(512,activation='relu'))\n","    model.add(Dense(64,activation='relu'))\n","    model.add(Dense(5, activation='softmax')) # Use softmax as one of the activations, crossentropy for loss\n","\n","    # Convert labels to categorical\n","    train_cancer_cat = to_categorical(train_cancer, num_classes=2) # 2 classes for \"1\" and \"0\"\n","    test_cancer_cat = to_categorical(test_cancer, num_classes=2)\n","\n","    # \"accuracy is training accuracy\"\n","    model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","    r2 = model.fit(train_img, train_cancer_cat, epochs=7)\n","\n","    model.summary()\n","\n","    # Plotting losses\n","    plt.close()\n","    plt.plot(r2.history['loss'], label='loss for'+ title)\n","    plt.legend(loc=\"upper left\")\n","    plt.title('Loss over epoch for' + title )\n","    plt.show()\n","    plt.close()\n","\n","    # Plotting accuracy\n","    plt.plot(r2.history['accuracy'], label='accuracy for '+ title)\n","    plt.legend(loc=\"upper left\")\n","    plt.title('Accuracy over epoch' + title)\n","    plt.show()\n","\n","    y_pred = model.predict(test_img)\n","    y_pred = np.argmax(y_pred, axis=1)\n","\n","    cm = confusion_matrix(np.array(testing['cancer']), y_pred)\n","\n","    # Plotting the Confusion Matrix\n","    plt.figure(figsize=(10, 7))\n","    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n","      xticklabels=['Tumor present', 'No tumor present'],\n","      yticklabels=['Tumor present', 'No tumor present'])\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title(f'Confusion Matrix for {title}')\n","    plt.show()\n","\n","    print(classification_report(y_true=np.array(testing['cancer']), y_pred=y_pred))\n","    print(categorical_accuracies(y_true=np.array(testing['cancer']), y_pred=y_pred))\n","\n","    print(count_unique_values(np.array(testing['cancer'])))\n","    print(count_unique_values(y_pred))\n","\n","    print('training accuracies')\n","    print(r2.history[\"accuracy\"][-1])\n","    y_true = np.array(training['cancer'])\n","    y_pred = model.predict(train_img)\n","    y_pred = np.argmax(y_pred, axis=1)\n","    print(classification_report(y_true=y_true, y_pred=y_pred))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/yc/Documents/DL/final/big_helper.py:8: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n","dict_items([('1.3.6.1.4.1.14519.5.2.1.6655.2359.289186849349654450104973032531.xml', array([[293., 318., 348., 384.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.218387194706247505045205169130.xml', array([[287., 315., 355., 387.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.191468104323452587789797624004.xml', array([[285., 319., 355., 389.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.185555685346057091761687385642.xml', array([[298., 298., 335., 374.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.184131899543495374569818432657.xml', array([[301., 329., 351., 372.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.136943255924913899762603730997.xml', array([[278., 308., 360., 394.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.592450921957945360354404357368.xml', array([[292., 301., 338., 379.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.216515627058008697217695696166.xml', array([[288., 313., 351., 380.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.264364194296293440320787350583.xml', array([[287., 324., 354., 377.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.217649008723153656849717286154.xml', array([[290., 315., 359., 393.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.326712390675165848304281961959.xml', array([[287., 313., 349., 385.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.301905642463494729146015070819.xml', array([[282., 307., 355., 388.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.155870813347987660555133803380.xml', array([[290., 305., 338., 378.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.223280971440388131399634898721.xml', array([[286., 317., 354., 388.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.187586942311847648079258238193.xml', array([[287., 300., 342., 379.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.103293611003651848123608366756.xml', array([[304., 304., 337., 372.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.102500633407588554681658808214.xml', array([[286., 310., 355., 402.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.241073611031000247506142606387.xml', array([[281., 307., 357., 394.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.253763111879303517159545374933.xml', array([[289., 317., 353., 391.,   1.,   0.,   0.,   0.]])), ('1.3.6.1.4.1.14519.5.2.1.6655.2359.741206086241237558496042747969.xml', array([[296., 331., 351., 382.,   1.,   0.,   0.,   0.]]))])\n"]}],"source":["import os\n","import subprocess\n","!find . -name \".DS_Store\" -delete\n","\n","# TODO: Need to make a for-loop that goes through every folder in images and annotations. This is \n","# because the way the code works, it only goes through one folder at a time, so we need a loop\n","# that calls big_helper.py multiple times. I don't care about runtime anymore...\n","\n","# NOTE: There will be Not-Found errors because not all the image files are downloaded even though all\n","# the annotations are downloaded.\n","\n","# for folder in os.listdir(\"dl_data/annotations\"):\n","#     print(folder)\n","#     print(dicom_path)\n","#     dicom_path = f\"dl_data/images/Lung_Dx-{folder}\"\n","#     annotation_path = f\"dl_data/annotations/{folder}\" \n","    \n","#     command = [\n","#         \"python\", \"big_helper.py\", \"--dicom-mode\", \"CT\",\n","#         \"--dicom-path\", dicom_path,\n","#         \"--annotation-path\", annotation_path,\n","#         \"--classfile\", \"category.txt\"\n","#     ]\n","    \n","#     # Execute the command\n","#     subprocess.run(command)\n","\n","!python preprocess.py --dicom-mode CT --dicom-path dl_data/images/Lung_Dx-A0001 --annotation-path dl_data/annotations/A0001 --classfile category.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLqQYoSrW61l"},"outputs":[],"source":["#old code\n","basecase = {\"training\": pd.read_csv(\"/content/drive/MyDrive/S6/dl_final_project/base_training.csv\"),\n","            \"testing\": pd.read_csv(\"/content/drive/MyDrive/S6/dl_final_project/base_testing.csv\"),\n","            \"title\": 'basecase'}\n","\n","make_model(basecase)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1lr8P0n645eiGh1qg0dLU94-nq-32xY3Q","timestamp":1712890349126}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
