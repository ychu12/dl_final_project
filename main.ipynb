{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1714078756087,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"bHwsJ_pM7r1l","outputId":"f7bf6840-d468-47aa-e711-2a942242d675"},"outputs":[],"source":["# Helpfull code from https://www.kaggle.com/code/abhijitsingh001/predicting-gender-of-images/notebook\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import warnings\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,BatchNormalization\n","from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\n","from keras.optimizers import SGD,RMSprop\n","from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n","\n","from keras.models import Sequential\n","warnings.filterwarnings('ignore')\n","\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","from keras.layers import Dropout"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":109,"status":"ok","timestamp":1714078759312,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"aOahQ-FONXZj"},"outputs":[],"source":["# Converting the pixel data\n","def value_to_image(pixels):\n","    pixels = np.array(pixels.split(),'float64')\n","    pixels = np.reshape(pixels,(48,48))\n","    pixels = pixels / 255.0\n","    return pixels"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":111,"status":"ok","timestamp":1714078760800,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"2niVXpR3eJap"},"outputs":[],"source":["def categorical_accuracies(y_true, y_pred):\n","  # sanity check\n","  if len(y_true) != len(y_pred):\n","    print(\"y_true and y_pred are of different lengths\")\n","    return\n","\n","  correctness_tracker = {0:0, 1:0,2:0,3:0,4:0}\n","  sum_tracker = {0:0, 1:0,2:0,3:0,4:0}\n","  for i in range(0,len(y_true)):\n","    sum_tracker[y_true[i]] +=1\n","    if y_true[i] == y_pred[i]:\n","      correctness_tracker[y_true[i]] += 1\n","\n","  accuracy = {}\n","  for key in range(0,5):\n","    accuracy[key] = correctness_tracker[key] / sum_tracker[key] if sum_tracker[key] >0 else 0\n","  return accuracy\n","\n","def count_unique_values(array):\n","  counter = {0:0, 1:0,2:0,3:0,4:0}\n","  for element in array:\n","    counter[element] +=1\n","\n","  return counter"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1714078988868,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"y7JxTVYYQ_xE"},"outputs":[],"source":["'''\n","Data: a dictionary of training and testing\n","  Training: a pandas table of the original dataset\n","  Testing: a pandas table of the original dataset\n","'''\n","\n","# Changing dimensions of the data\n","def change_image_dimension(data):\n","    data = np.reshape(data.to_list(),(len(data),48,48,1))\n","    return data\n","\n","def make_model(data):\n","    training = data[\"training\"]\n","    testing = data['testing']\n","    title = data['title']\n","    train_img = training['pixels'].apply(value_to_image)\n","    test_img = testing['pixels'].apply(value_to_image)\n","\n","    train_cancer = training['cancer'] # 1 = there is a tumor, 0 = no tumor\n","    test_cancer = testing['cancer']\n","\n","    train_img = change_image_dimension(train_img)\n","    test_img = change_image_dimension(test_img)\n","\n","    train_img = train_img/255.0\n","    test_img = test_img/255.0\n","\n","    # CNN\n","    model=Sequential()\n","    model.add(Conv2D(256,(3,3),activation='relu',padding='same',input_shape=(48,48,1)))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(512,activation='relu'))\n","    model.add(Dense(64,activation='relu'))\n","    model.add(Dense(5, activation='softmax')) # Use softmax as one of the activations, crossentropy for loss\n","\n","    # Convert labels to categorical\n","    train_cancer_cat = to_categorical(train_cancer, num_classes=2) # 2 classes for \"1\" and \"0\"\n","    test_cancer_cat = to_categorical(test_cancer, num_classes=2)\n","\n","    # \"accuracy is training accuracy\"\n","    model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","    r2 = model.fit(train_img, train_cancer_cat, epochs=7)\n","\n","    model.summary()\n","\n","    # Plotting losses\n","    plt.close()\n","    plt.plot(r2.history['loss'], label='loss for'+ title)\n","    plt.legend(loc=\"upper left\")\n","    plt.title('Loss over epoch for' + title )\n","    plt.show()\n","    plt.close()\n","\n","    # Plotting accuracy\n","    plt.plot(r2.history['accuracy'], label='accuracy for '+ title)\n","    plt.legend(loc=\"upper left\")\n","    plt.title('Accuracy over epoch' + title)\n","    plt.show()\n","\n","    y_pred = model.predict(test_img)\n","    y_pred = np.argmax(y_pred, axis=1)\n","\n","    cm = confusion_matrix(np.array(testing['cancer']), y_pred)\n","\n","    # Plotting the Confusion Matrix\n","    plt.figure(figsize=(10, 7))\n","    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n","      xticklabels=['Tumor present', 'No tumor present'],\n","      yticklabels=['Tumor present', 'No tumor present'])\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title(f'Confusion Matrix for {title}')\n","    plt.show()\n","\n","    print(classification_report(y_true=np.array(testing['cancer']), y_pred=y_pred))\n","    print(categorical_accuracies(y_true=np.array(testing['cancer']), y_pred=y_pred))\n","\n","    print(count_unique_values(np.array(testing['cancer'])))\n","    print(count_unique_values(y_pred))\n","\n","    print('training accuracies')\n","    print(r2.history[\"accuracy\"][-1])\n","    y_true = np.array(training['cancer'])\n","    y_pred = model.predict(train_img)\n","    y_pred = np.argmax(y_pred, axis=1)\n","    print(classification_report(y_true=y_true, y_pred=y_pred))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["A0174\n","A0180\n","E0001\n","G0062\n","A0187\n","A0173\n","G0054\n","A0145\n","A0189\n","A0142\n","G0053\n","A0116\n","G0007\n","A0129\n","G0038\n","A0111\n","G0036\n","A0127\n","G0009\n","A0118\n","A0120\n","G0031\n","A0188\n","G0052\n","A0143\n","A0144\n","G0055\n","A0181\n","A0175\n","G0030\n","A0121\n","A0126\n","G0037\n","A0119\n","G0008\n","A0110\n","G0001\n","G0006\n","A0117\n","G0039\n","A0128\n","A0065\n","A0257\n","A0091\n","A0096\n","A0250\n","A0062\n","A0259\n","A0266\n","A0054\n","A0098\n","A0053\n","A0261\n","A0235\n","A0007\n","A0038\n","B0037\n","A0232\n","B0008\n","B0001\n","A0036\n","A0204\n","A0009\n","A0203\n","A0031\n","B0006\n","A0099\n","A0260\n","A0052\n","A0258\n","A0055\n","A0063\n","A0097\n","A0090\n","A0256\n","A0064\n","B0007\n","A0030\n","A0202\n","B0038\n","A0205\n","A0037\n","A0008\n","A0233\n","A0001\n","B0036\n","B0009\n","B0031\n","A0006\n","A0234\n","A0039\n","A0229\n","B0013\n","A0216\n","A0024\n","A0023\n","A0211\n","B0014\n","A0218\n","A0015\n","A0227\n","B0022\n","B0025\n","A0220\n","A0012\n","A0046\n","A0041\n","A0077\n","B0040\n","A0083\n","A0048\n","A0084\n","A0070\n","A0242\n","A0013\n","A0221\n","B0024\n","B0023\n","A0226\n","A0014\n","B0015\n","A0210\n","A0022\n","A0228\n","A0025\n","A0217\n","B0012\n","A0243\n","A0071\n","A0085\n","B0041\n","A0082\n","A0076\n","A0244\n","A0049\n","A0040\n","A0047\n","A0078\n","G0024\n","A0135\n","A0132\n","G0023\n","A0104\n","G0015\n","G0012\n","A0103\n","G0046\n","A0157\n","A0168\n","A0150\n","G0041\n","A0166\n","A0192\n","A0159\n","G0048\n","A0195\n","A0161\n","A0102\n","G0013\n","G0014\n","A0105\n","G0022\n","A0133\n","A0134\n","G0025\n","A0160\n","A0194\n","A0193\n","A0167\n","G0049\n","G0040\n","A0156\n","G0047\n","A0169\n","G0003\n","A0112\n","A0115\n","G0004\n","A0123\n","G0032\n","G0035\n","A0124\n","E0002\n","A0184\n","A0170\n","A0148\n","G0059\n","A0177\n","A0183\n","E0005\n","A0141\n","G0050\n","A0179\n","G0057\n","A0146\n","A0125\n","G0034\n","G0033\n","G0005\n","A0114\n","A0113\n","G0002\n","A0178\n","A0147\n","G0056\n","G0051\n","A0140\n","G0058\n","A0149\n","A0182\n","E0004\n","A0176\n","A0171\n","E0003\n","A0185\n","G0060\n","B0034\n","A0231\n","A0003\n","A0004\n","A0236\n","B0033\n","A0032\n","A0200\n","B0005\n","B0002\n","A0035\n","A0238\n","A0095\n","A0061\n","A0253\n","A0059\n","A0254\n","A0066\n","A0092\n","A0262\n","A0050\n","A0068\n","A0057\n","A0265\n","A0034\n","A0206\n","B0003\n","A0239\n","B0004\n","A0201\n","A0033\n","A0237\n","A0005\n","A0208\n","A0002\n","A0230\n","A0069\n","A0264\n","A0056\n","A0051\n","A0263\n","A0058\n","A0093\n","A0067\n","A0255\n","A0252\n","A0060\n","A0094\n","A0042\n","A0089\n","A0045\n","A0248\n","A0087\n","B0044\n","A0241\n","A0073\n","A0074\n","A0246\n","B0043\n","A0080\n","B0028\n","A0212\n","A0020\n","B0017\n","A0018\n","A0027\n","B0019\n","B0026\n","A0011\n","A0223\n","A0029\n","A0224\n","A0016\n","B0021\n","B0042\n","A0081\n","A0247\n","A0075\n","A0072\n","A0240\n","A0086\n","A0044\n","A0249\n","A0043\n","A0088\n","A0028\n","B0020\n","A0017\n","A0225\n","B0018\n","A0222\n","A0010\n","B0027\n","A0019\n","A0214\n","A0026\n","B0011\n","B0016\n","A0021\n","A0213\n","A0153\n","G0042\n","A0198\n","G0045\n","A0154\n","A0196\n","A0162\n","A0165\n","A0191\n","A0131\n","G0020\n","G0018\n","A0109\n","G0027\n","A0136\n","G0011\n","A0100\n","A0138\n","G0029\n","A0107\n","G0016\n","A0190\n","A0164\n","A0163\n","A0197\n","A0155\n","G0044\n","G0043\n","A0152\n","A0199\n","G0028\n","A0139\n","G0017\n","A0106\n","A0101\n","G0010\n","A0108\n","G0019\n","A0137\n","G0026\n","G0021\n","A0130\n"]}],"source":["import os\n","import subprocess\n","!find . -name \".DS_Store\" -delete\n","\n","# TODO: Need to make a for-loop that goes through every folder in images and annotations. This is \n","# because the way the code works, it only goes through one folder at a time, so we need a loop\n","# that calls big_helper.py multiple times. I don't care about runtime anymore...\n","\n","# NOTE: There will be Not-Found errors because not all the image files are downloaded even though all\n","# the annotations are downloaded.\n","\n","# # Some of the stencil code uses depricated code, but it is still needed\n","# import warnings\n","# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","for folder in os.listdir(\"dl_data/annotations\"):\n","    dicom_path = f\"dl_data/images/Lung_Dx-{folder}\"\n","    annotation_path = f\"dl_data/annotations/{folder}\" \n","\n","    # Need to make this if-statement dynamic\n","    if folder != \"A0001\" or folder != \"A0002\" or folder != \"A0003\" or folder != \"A0004\":\n","        continue\n","    else:\n","        print(folder)\n","    \n","    command = [\n","        \"python\", \"preprocess.py\", \"--dicom-mode\", \"CT\",\n","        \"--dicom-path\", dicom_path,\n","        \"--annotation-path\", annotation_path,\n","        \"--classfile\", \"category.txt\"\n","    ]\n","    \n","    # Execute the command\n","    subprocess.run(command)\n","\n","#!python preprocess.py --dicom-mode CT --dicom-path dl_data/images/Lung_Dx-A0001 --annotation-path dl_data/annotations/A0001 --classfile category.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLqQYoSrW61l"},"outputs":[],"source":["#old code\n","basecase = {\"training\": pd.read_csv(\"/content/drive/MyDrive/S6/dl_final_project/base_training.csv\"),\n","            \"testing\": pd.read_csv(\"/content/drive/MyDrive/S6/dl_final_project/base_testing.csv\"),\n","            \"title\": 'basecase'}\n","\n","make_model(basecase)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1lr8P0n645eiGh1qg0dLU94-nq-32xY3Q","timestamp":1712890349126}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
