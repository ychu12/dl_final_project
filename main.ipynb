{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1714078756087,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"bHwsJ_pM7r1l","outputId":"f7bf6840-d468-47aa-e711-2a942242d675"},"outputs":[],"source":["# Helpfull code from https://www.kaggle.com/code/abhijitsingh001/predicting-gender-of-images/notebook\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import warnings\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,BatchNormalization\n","from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\n","from keras.optimizers import SGD,RMSprop\n","from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n","\n","from keras.models import Sequential\n","warnings.filterwarnings('ignore')\n","\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","from keras.layers import Dropout"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":109,"status":"ok","timestamp":1714078759312,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"aOahQ-FONXZj"},"outputs":[],"source":["# Converting the pixel data\n","def value_to_image(pixels):\n","    pixels = np.array(pixels.split(),'float64')\n","    pixels = np.reshape(pixels,(48,48))\n","    pixels = pixels / 255.0\n","    return pixels"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":111,"status":"ok","timestamp":1714078760800,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"2niVXpR3eJap"},"outputs":[],"source":["def categorical_accuracies(y_true, y_pred):\n","  # sanity check\n","  if len(y_true) != len(y_pred):\n","    print(\"y_true and y_pred are of different lengths\")\n","    return\n","\n","  correctness_tracker = {0:0, 1:0,2:0,3:0,4:0}\n","  sum_tracker = {0:0, 1:0,2:0,3:0,4:0}\n","  for i in range(0,len(y_true)):\n","    sum_tracker[y_true[i]] +=1\n","    if y_true[i] == y_pred[i]:\n","      correctness_tracker[y_true[i]] += 1\n","\n","  accuracy = {}\n","  for key in range(0,5):\n","    accuracy[key] = correctness_tracker[key] / sum_tracker[key] if sum_tracker[key] >0 else 0\n","  return accuracy\n","\n","def count_unique_values(array):\n","  counter = {0:0, 1:0,2:0,3:0,4:0}\n","  for element in array:\n","    counter[element] +=1\n","\n","  return counter"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1714078988868,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"y7JxTVYYQ_xE"},"outputs":[],"source":["'''\n","Data: a dictionary of training and testing\n","  Training: a pandas table of the original dataset\n","  Testing: a pandas table of the original dataset\n","'''\n","\n","# Changing dimensions of the data\n","def change_image_dimension(data):\n","    data = np.reshape(data.to_list(),(len(data),48,48,1))\n","    return data\n","\n","def make_model(data):\n","    training = data[\"training\"]\n","    testing = data['testing']\n","    title = data['title']\n","    train_img = training['Pixel Data'].apply(value_to_image)\n","    test_img = testing['Pixel Data'].apply(value_to_image)\n","\n","    train_cancer = training['Cancer Type']\n","    test_cancer = testing['Cancer Type']\n","\n","    train_img = change_image_dimension(train_img)\n","    test_img = change_image_dimension(test_img)\n","\n","    train_img = train_img/255.0\n","    test_img = test_img/255.0\n","\n","    # CNN\n","    model=Sequential()\n","    model.add(Conv2D(256,(3,3),activation='relu',padding='same',input_shape=(48,48,1)))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n","    model.add(MaxPool2D(2,2))\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(512,activation='relu'))\n","    model.add(Dense(64,activation='relu'))\n","    model.add(Dense(5, activation='softmax')) # Use softmax as one of the activations, crossentropy for loss\n","\n","    # Convert labels to categorical\n","    train_cancer_cat = to_categorical(train_cancer, num_classes=2) # 2 classes for \"1\" and \"0\"\n","    test_cancer_cat = to_categorical(test_cancer, num_classes=2)\n","\n","    # \"accuracy is training accuracy\"\n","    model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","    r2 = model.fit(train_img, train_cancer_cat, epochs=7)\n","\n","    model.summary()\n","\n","    # Plotting losses\n","    plt.close()\n","    plt.plot(r2.history['loss'], label='loss for'+ title)\n","    plt.legend(loc=\"upper left\")\n","    plt.title('Loss over epoch for' + title )\n","    plt.show()\n","    plt.close()\n","\n","    # Plotting accuracy\n","    plt.plot(r2.history['accuracy'], label='accuracy for '+ title)\n","    plt.legend(loc=\"upper left\")\n","    plt.title('Accuracy over epoch' + title)\n","    plt.show()\n","\n","    y_pred = model.predict(test_img)\n","    y_pred = np.argmax(y_pred, axis=1)\n","\n","    cm = confusion_matrix(np.array(testing['Cancer Type']), y_pred)\n","\n","    # Plotting the Confusion Matrix (TODO: Relabel and redo)\n","    plt.figure(figsize=(10, 7))\n","    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n","      xticklabels=['Tumor present', 'No tumor present'],\n","      yticklabels=['Tumor present', 'No tumor present'])\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title(f'Confusion Matrix for {title}')\n","    plt.show()\n","\n","    print(classification_report(y_true=np.array(testing['Cancer Type']), y_pred=y_pred))\n","    print(categorical_accuracies(y_true=np.array(testing['Cancer Type']), y_pred=y_pred))\n","\n","    print(count_unique_values(np.array(testing['Cancer Type'])))\n","    print(count_unique_values(y_pred))\n","\n","    print('training accuracies')\n","    print(r2.history[\"accuracy\"][-1])\n","    y_true = np.array(training['Cancer Type'])\n","    y_pred = model.predict(train_img)\n","    y_pred = np.argmax(y_pred, axis=1)\n","    print(classification_report(y_true=y_true, y_pred=y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import subprocess\n","!find . -name \".DS_Store\" -delete\n","\n","# TODO: Need to make a for-loop that goes through every folder in images and annotations. This is \n","# because the way the code works, it only goes through one folder at a time, so we need a loop\n","# that calls big_helper.py multiple times. I don't care about runtime anymore...\n","\n","# NOTE: There will be Not-Found errors because not all the image files are downloaded even though all\n","# the annotations are downloaded.\n","\n","# # Some of the stencil code uses depricated code, but it is still needed\n","# import warnings\n","# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# This code block basically preprocesses the image data and puts it into a CSV file\n","for folder in os.listdir(\"dl_data/annotations\"):\n","    dicom_path = f\"dl_data/images/Lung_Dx-{folder}\"\n","    annotation_path = f\"dl_data/annotations/{folder}\" \n","\n","    folder_list = ['A0001', 'A0002', 'A0003', 'A0004', 'A0005']\n","    \n","    if folder not in folder_list:\n","        continue\n","    else:\n","        print(folder)\n","    \n","    command = [\n","        \"python\", \"preprocess.py\", \"--dicom-mode\", \"CT\",\n","        \"--dicom-path\", dicom_path,\n","        \"--annotation-path\", annotation_path,\n","        \"--classfile\", \"category.txt\"\n","    ]\n","    \n","    # Execute the command\n","    subprocess.run(command)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# This code block will do a train/test split on the data and export it to respective csv files\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","def split(df, export_train_path, export_test_path):\n","    X = df['Pixel Data']\n","    y = df['Cancer Type']\n","    \n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=31)\n","\n","    X_train = pd.DataFrame(X_train)\n","    X_train['Cancer Type'] = y_train\n","\n","    X_test = pd.DataFrame(X_test)\n","    X_test['Cancer Type'] = y_test\n","\n","    X_train.to_csv(export_train_path, index=False)\n","    X_test.to_csv(export_test_path, index=False)\n","\n","data = pd.read_csv('base.csv')\n","data = data[['File Name', 'Pixel Data', 'Cancer Type']]\n","\n","split(data, 'base_train.csv', 'base_test.csv')"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"dLqQYoSrW61l"},"outputs":[{"ename":"ValueError","evalue":"cannot reshape array of size 262144 into shape (48,48)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#old code\u001b[39;00m\n\u001b[1;32m      2\u001b[0m basecase \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasecase\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasecase\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mmake_model\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m testing \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m title \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m train_img \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPixel Data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_to_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m test_img \u001b[38;5;241m=\u001b[39m testing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPixel Data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(value_to_image)\n\u001b[1;32m     19\u001b[0m train_cancer \u001b[38;5;241m=\u001b[39m training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancer Type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mvalue_to_image\u001b[0;34m(pixels)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_to_image\u001b[39m(pixels):\n\u001b[1;32m      3\u001b[0m     pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pixels\u001b[38;5;241m.\u001b[39msplit(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     pixels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     pixels \u001b[38;5;241m=\u001b[39m pixels \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pixels\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/numpy/core/fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 262144 into shape (48,48)"]}],"source":["#old code\n","basecase = {\"training\": pd.read_csv(\"base_train.csv\"),\n","            \"testing\": pd.read_csv(\"base_test.csv\"),\n","            \"title\": 'basecase'}\n","\n","make_model(basecase)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1lr8P0n645eiGh1qg0dLU94-nq-32xY3Q","timestamp":1712890349126}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
