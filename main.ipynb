{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1714078756087,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"bHwsJ_pM7r1l","outputId":"f7bf6840-d468-47aa-e711-2a942242d675"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import warnings\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,BatchNormalization\n","from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\n","from keras.optimizers import SGD,RMSprop\n","from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n","\n","from keras.models import Sequential\n","warnings.filterwarnings('ignore')\n","\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","from keras.layers import Dropout"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","def display_images(desired_shape, images, num_images=6):\n","    plt.figure(figsize=(12, 6))\n","    for i in range(num_images):\n","        ax = plt.subplot(2, 3, i + 1)\n","        plt.imshow(images[i].reshape(desired_shape[0], desired_shape[1]), cmap='gray')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","def process_pixel_data(pixel_data, desired_shape):\n","    return np.array([np.array([float(x) for x in item.split()]).reshape(desired_shape) for item in pixel_data])\n","\n","def process_labels(labels):\n","    # Convert labels to numerical format if they're not numeric\n","    unique_labels = {label: idx for idx, label in enumerate(np.unique(labels))}\n","    return np.array([unique_labels[label] for label in labels]), unique_labels\n","\n","def make_model(pixel_data, labels):\n","    # Process pixel data\n","    input_shape = (64, 64, 1) # Corresponds to target_size in preprocess.py, but with an added dimension\n","    processed_images = process_pixel_data(pixel_data, desired_shape=input_shape)\n","\n","    # display_images(input_shape, processed_images)\n","\n","    # Process labels\n","    processed_labels, label_map = process_labels(labels)\n","    processed_labels = to_categorical(processed_labels)\n","\n","    # Splitting data into training and testing sets\n","    train_img, test_img, train_cancer_cat, test_cancer_cat = train_test_split(\n","        processed_images, processed_labels, test_size=0.2, random_state=42)\n","    \n","    # CNN Model\n","    model = Sequential([\n","        Conv2D(256, (3,3), activation='relu', padding='same', input_shape=input_shape),\n","        MaxPool2D(2,2),\n","        BatchNormalization(),\n","        Conv2D(64, (3,3), activation='relu', padding='same'),\n","        MaxPool2D(2,2),\n","        BatchNormalization(),\n","        Conv2D(32, (3,3), activation='relu', padding='same'),\n","        MaxPool2D(2,2),\n","        BatchNormalization(),\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dense(64, activation='relu'),\n","        Dense(len(label_map), activation='softmax') \n","    ])\n","\n","    model.compile(optimizer=Adam(learning_rate=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n","    history = model.fit(train_img, train_cancer_cat, validation_data=(test_img, test_cancer_cat), epochs=20)\n","\n","    # Evaluation and reporting\n","    print(\"Training Accuracy:\", history.history['accuracy'][-1])\n","    print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n","\n","    # Evaluation\n","    print(\"Training accuracies:\")\n","    print(history.history[\"accuracy\"][-1])\n","\n","    return model, label_map, history\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["E0001\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","A0001\n","Folder/File Found\n","G0004\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","E0002\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","G0005\n","Folder/File Found\n","A0003\n","Folder/File Found\n","A0004\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","B0005\n","Folder/File Found\n","B0004\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","A0005\n","Folder/File Found\n","Possible key error\n","Possible key error\n","A0002\n","Folder/File Found\n"]}],"source":["import os\n","import subprocess\n","!find . -name \".DS_Store\" -delete\n","\n","# TODO: Need to make a for-loop that goes through every folder in images and annotations. This is \n","# because the way the code works, it only goes through one folder at a time, so we need a loop\n","# that calls big_helper.py multiple times. I don't care about runtime anymore...\n","\n","# NOTE: There will be Not-Found errors because not all the image files are downloaded even though all\n","# the annotations are downloaded.\n","\n","# # Some of the stencil code uses depricated code, but it is still needed\n","# import warnings\n","# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# This code block basically preprocesses the image data and puts it into a CSV file\n","for folder in os.listdir(\"dl_data/annotations\"):\n","    dicom_path = f\"dl_data/images/Lung_Dx-{folder}\"\n","    annotation_path = f\"dl_data/annotations/{folder}\" \n","\n","    folder_list = ['A0001', 'A0002', 'A0003', 'A0004', 'A0005', 'B0004', 'B0005', 'E0001', 'E0002', 'G0004', 'G0005']\n","    \n","    if folder not in folder_list:\n","        continue\n","    else:\n","        print(folder)\n","    \n","    command = [\n","        \"python\", \"preprocess.py\", \"--dicom-mode\", \"CT\",\n","        \"--dicom-path\", dicom_path,\n","        \"--annotation-path\", annotation_path,\n","        \"--classfile\", \"category.txt\"\n","    ]\n","    \n","    # Execute the command\n","    subprocess.run(command)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"dLqQYoSrW61l"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","4/4 [==============================] - 2s 371ms/step - loss: 4.8095 - accuracy: 0.4519 - val_loss: 3004.6367 - val_accuracy: 0.3846\n","Epoch 2/40\n","4/4 [==============================] - 1s 333ms/step - loss: 0.7225 - accuracy: 0.8173 - val_loss: 2508.3896 - val_accuracy: 0.3846\n","Epoch 3/40\n","4/4 [==============================] - 1s 304ms/step - loss: 0.3920 - accuracy: 0.9423 - val_loss: 1242.2587 - val_accuracy: 0.3846\n","Epoch 4/40\n","4/4 [==============================] - 1s 305ms/step - loss: 0.0921 - accuracy: 0.9615 - val_loss: 804.7913 - val_accuracy: 0.5769\n","Epoch 5/40\n","4/4 [==============================] - 1s 302ms/step - loss: 0.2063 - accuracy: 0.9904 - val_loss: 611.8529 - val_accuracy: 0.3846\n","Epoch 6/40\n","4/4 [==============================] - 1s 307ms/step - loss: 1.9147e-04 - accuracy: 1.0000 - val_loss: 676.8092 - val_accuracy: 0.3846\n","Epoch 7/40\n","4/4 [==============================] - 1s 309ms/step - loss: 3.3831e-05 - accuracy: 1.0000 - val_loss: 653.1523 - val_accuracy: 0.3846\n","Epoch 8/40\n","4/4 [==============================] - 1s 303ms/step - loss: 0.0485 - accuracy: 0.9712 - val_loss: 385.2198 - val_accuracy: 0.3846\n","Epoch 9/40\n","4/4 [==============================] - 1s 305ms/step - loss: 5.4331e-06 - accuracy: 1.0000 - val_loss: 274.6926 - val_accuracy: 0.5385\n","Epoch 10/40\n","4/4 [==============================] - 1s 310ms/step - loss: 0.2312 - accuracy: 0.9904 - val_loss: 255.8331 - val_accuracy: 0.5385\n","Epoch 11/40\n","4/4 [==============================] - 1s 318ms/step - loss: 0.0814 - accuracy: 0.9904 - val_loss: 271.7547 - val_accuracy: 0.4615\n","Epoch 12/40\n","4/4 [==============================] - 2s 328ms/step - loss: 3.4846e-07 - accuracy: 1.0000 - val_loss: 286.5717 - val_accuracy: 0.3846\n","Epoch 13/40\n","4/4 [==============================] - 1s 333ms/step - loss: 4.1949e-06 - accuracy: 1.0000 - val_loss: 281.5936 - val_accuracy: 0.3846\n","Epoch 14/40\n","4/4 [==============================] - 1s 314ms/step - loss: 8.2688e-04 - accuracy: 1.0000 - val_loss: 261.6810 - val_accuracy: 0.3846\n","Epoch 15/40\n","4/4 [==============================] - 1s 320ms/step - loss: 1.7583e-06 - accuracy: 1.0000 - val_loss: 235.2395 - val_accuracy: 0.3846\n","Epoch 16/40\n","4/4 [==============================] - 1s 301ms/step - loss: 1.2299e-04 - accuracy: 1.0000 - val_loss: 210.6661 - val_accuracy: 0.3846\n","Epoch 17/40\n","4/4 [==============================] - 1s 309ms/step - loss: 7.6532e-05 - accuracy: 1.0000 - val_loss: 189.0439 - val_accuracy: 0.3846\n","Epoch 18/40\n","4/4 [==============================] - 1s 301ms/step - loss: 7.9548e-05 - accuracy: 1.0000 - val_loss: 168.9456 - val_accuracy: 0.3846\n","Epoch 19/40\n","4/4 [==============================] - 1s 307ms/step - loss: 7.3335e-05 - accuracy: 1.0000 - val_loss: 150.5103 - val_accuracy: 0.3846\n","Epoch 20/40\n","4/4 [==============================] - 1s 311ms/step - loss: 3.2715e-04 - accuracy: 1.0000 - val_loss: 133.8662 - val_accuracy: 0.3846\n","Epoch 21/40\n","4/4 [==============================] - 1s 305ms/step - loss: 1.5772e-05 - accuracy: 1.0000 - val_loss: 119.1522 - val_accuracy: 0.3846\n","Epoch 22/40\n","4/4 [==============================] - 1s 308ms/step - loss: 1.4006e-05 - accuracy: 1.0000 - val_loss: 105.6882 - val_accuracy: 0.3846\n","Epoch 23/40\n","4/4 [==============================] - 1s 306ms/step - loss: 3.8742e-06 - accuracy: 1.0000 - val_loss: 93.6818 - val_accuracy: 0.3846\n","Epoch 24/40\n","4/4 [==============================] - 1s 303ms/step - loss: 4.1996e-06 - accuracy: 1.0000 - val_loss: 83.1220 - val_accuracy: 0.3846\n","Epoch 25/40\n","4/4 [==============================] - 1s 313ms/step - loss: 2.9572e-06 - accuracy: 1.0000 - val_loss: 73.8506 - val_accuracy: 0.3846\n","Epoch 26/40\n","4/4 [==============================] - 1s 314ms/step - loss: 2.8059e-06 - accuracy: 1.0000 - val_loss: 65.5000 - val_accuracy: 0.3846\n","Epoch 27/40\n","4/4 [==============================] - 1s 320ms/step - loss: 2.9710e-06 - accuracy: 1.0000 - val_loss: 57.7405 - val_accuracy: 0.3846\n","Epoch 28/40\n","4/4 [==============================] - 1s 319ms/step - loss: 2.2580e-06 - accuracy: 1.0000 - val_loss: 50.5690 - val_accuracy: 0.3846\n","Epoch 29/40\n","4/4 [==============================] - 1s 304ms/step - loss: 1.1371e-06 - accuracy: 1.0000 - val_loss: 43.6585 - val_accuracy: 0.3846\n","Epoch 30/40\n","4/4 [==============================] - 1s 306ms/step - loss: 1.6884e-06 - accuracy: 1.0000 - val_loss: 37.6828 - val_accuracy: 0.4615\n","Epoch 31/40\n","4/4 [==============================] - 1s 305ms/step - loss: 2.3004e-06 - accuracy: 1.0000 - val_loss: 32.4856 - val_accuracy: 0.5000\n","Epoch 32/40\n","4/4 [==============================] - 1s 311ms/step - loss: 9.1928e-07 - accuracy: 1.0000 - val_loss: 27.8164 - val_accuracy: 0.5000\n","Epoch 33/40\n","4/4 [==============================] - 1s 302ms/step - loss: 1.2735e-06 - accuracy: 1.0000 - val_loss: 23.6665 - val_accuracy: 0.5000\n","Epoch 34/40\n","4/4 [==============================] - 1s 308ms/step - loss: 1.3961e-06 - accuracy: 1.0000 - val_loss: 19.8948 - val_accuracy: 0.5385\n","Epoch 35/40\n","4/4 [==============================] - 1s 311ms/step - loss: 9.1928e-07 - accuracy: 1.0000 - val_loss: 16.7364 - val_accuracy: 0.6154\n","Epoch 36/40\n","4/4 [==============================] - 1s 304ms/step - loss: 1.3640e-06 - accuracy: 1.0000 - val_loss: 14.3055 - val_accuracy: 0.6154\n","Epoch 37/40\n","4/4 [==============================] - 1s 311ms/step - loss: 6.4762e-07 - accuracy: 1.0000 - val_loss: 12.1868 - val_accuracy: 0.6538\n","Epoch 38/40\n","4/4 [==============================] - 1s 301ms/step - loss: 9.8117e-07 - accuracy: 1.0000 - val_loss: 10.3233 - val_accuracy: 0.6923\n","Epoch 39/40\n","4/4 [==============================] - 1s 302ms/step - loss: 9.8232e-07 - accuracy: 1.0000 - val_loss: 8.6548 - val_accuracy: 0.7692\n","Epoch 40/40\n","4/4 [==============================] - 1s 311ms/step - loss: 1.0477e-06 - accuracy: 1.0000 - val_loss: 7.3842 - val_accuracy: 0.7692\n","Training Accuracy: 1.0\n","Validation Accuracy: 0.7692307829856873\n","Training accuracies:\n","1.0\n"]}],"source":["data = pd.read_csv('output.csv')\n","model, label_map, history = make_model(data['pixel_data'], data['cancer_type'])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1lr8P0n645eiGh1qg0dLU94-nq-32xY3Q","timestamp":1712890349126}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
