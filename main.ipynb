{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1714078756087,"user":{"displayName":"Yen Chu","userId":"05587752232318816252"},"user_tz":240},"id":"bHwsJ_pM7r1l","outputId":"f7bf6840-d468-47aa-e711-2a942242d675"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import warnings\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,BatchNormalization\n","from keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\n","from keras.optimizers import SGD,RMSprop\n","from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n","\n","from keras.models import Sequential\n","warnings.filterwarnings('ignore')\n","\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam\n","from keras.layers import Dropout"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from keras.regularizers import l2\n","\n","def display_images(desired_shape, images, num_images=6):\n","    plt.figure(figsize=(12, 6))\n","    for i in range(num_images):\n","        ax = plt.subplot(2, 3, i + 1)\n","        plt.imshow(images[i].reshape(desired_shape[0], desired_shape[1]), cmap='gray')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","def process_pixel_data(pixel_data, desired_shape):\n","    return np.array([np.array([float(x) for x in item.split()]).reshape(desired_shape) for item in pixel_data])\n","\n","def process_labels(labels):\n","    # Convert labels to numerical format if they're not numeric\n","    unique_labels = {label: idx for idx, label in enumerate(np.unique(labels))}\n","    return np.array([unique_labels[label] for label in labels]), unique_labels\n","\n","def make_model(pixel_data, labels):\n","    # Process pixel data\n","    input_shape = (128, 128, 1) # Corresponds to target_size in preprocess.py, but with an added dimension\n","    processed_images = process_pixel_data(pixel_data, desired_shape=input_shape)\n","\n","    # display_images(input_shape, processed_images)\n","\n","    # Process labels\n","    processed_labels, label_map = process_labels(labels)\n","    processed_labels = to_categorical(processed_labels)\n","\n","    train_img, test_img, train_cancer_cat, test_cancer_cat = train_test_split(\n","    processed_images, processed_labels, test_size=0.2, random_state=42, stratify=None)\n","\n","    # # Splitting data into training and testing sets\n","    # train_img, test_img, train_cancer_cat, test_cancer_cat = train_test_split(\n","    #     processed_images, processed_labels, test_size=0.2, random_state=42)\n","    \n","    # CNN Model\n","    model = Sequential([\n","        Conv2D(256, (3,3), activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n","        MaxPool2D(2,2),\n","        BatchNormalization(),\n","        Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n","        MaxPool2D(2,2),\n","        BatchNormalization(),\n","        Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n","        MaxPool2D(2,2),\n","        BatchNormalization(),\n","        Flatten(),\n","        Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n","        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n","        Dense(len(label_map), activation='softmax') \n","    ])\n","\n","    model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","    history = model.fit(train_img, train_cancer_cat, validation_data=(test_img, test_cancer_cat), epochs=20)\n","\n","    # Evaluation and reporting\n","    print(\"Training Accuracy:\", history.history['accuracy'][-1])\n","    print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n","\n","    # Evaluation\n","    print(\"Training accuracies:\")\n","    print(history.history[\"accuracy\"][-1])\n","\n","    # mlp_model = Sequential([\n","    #     Flatten(input_shape=input_shape),\n","    #     Dense(512, activation='relu'),\n","    #     Dropout(0.5),\n","    #     Dense(256, activation='relu'),\n","    #     Dropout(0.5),\n","    #     Dense(128, activation='relu'),\n","    #     Dropout(0.5),\n","    #     Dense(len(label_map), activation='softmax')\n","    # ])\n","\n","    # mlp_model.compile(\n","    #     optimizer=Adam(learning_rate=0.001),\n","    #     loss='categorical_crossentropy',\n","    #     metrics=['accuracy']\n","    # )\n","\n","    # mlp_history = mlp_model.fit(\n","    #     train_img, train_cancer_cat,\n","    #     validation_data=(test_img, test_cancer_cat),\n","    #     epochs=30\n","    # )\n","\n","    # # Evaluation and reporting\n","    # print(\"Training Accuracy:\", mlp_history.history['accuracy'][-1])\n","    # print(\"Validation Accuracy:\", mlp_history.history['val_accuracy'][-1])\n","\n","    # # Evaluation\n","    # print(\"Training accuracies:\")\n","    # print(mlp_history.history[\"accuracy\"][-1])\n","\n","    # return model, label_map, history\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["E0001\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","A0001\n","Folder/File Found\n","G0004\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","E0002\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","G0005\n","Folder/File Found\n","A0003\n","Folder/File Found\n","A0004\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","B0005\n","Folder/File Found\n","B0004\n","Folder/File Found\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","Possible key error\n","A0005\n","Folder/File Found\n","Possible key error\n","Possible key error\n","A0002\n","Folder/File Found\n"]}],"source":["import os\n","import subprocess\n","!find . -name \".DS_Store\" -delete\n","\n","# TODO: Need to make a for-loop that goes through every folder in images and annotations. This is \n","# because the way the code works, it only goes through one folder at a time, so we need a loop\n","# that calls big_helper.py multiple times. I don't care about runtime anymore...\n","\n","# NOTE: There will be Not-Found errors because not all the image files are downloaded even though all\n","# the annotations are downloaded.\n","\n","# # Some of the stencil code uses depricated code, but it is still needed\n","# import warnings\n","# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# This code block basically preprocesses the image data and puts it into a CSV file\n","for folder in os.listdir(\"dl_data/annotations\"):\n","    dicom_path = f\"dl_data/images/Lung_Dx-{folder}\"\n","    annotation_path = f\"dl_data/annotations/{folder}\" \n","\n","    folder_list = ['A0001', 'A0002', 'A0003', 'A0004', 'A0005', 'B0004', 'B0005', 'E0001', 'E0002', 'G0004', 'G0005']\n","    \n","    if folder not in folder_list:\n","        continue\n","    else:\n","        print(folder)\n","    \n","    command = [\n","        \"python\", \"preprocess.py\", \"--dicom-mode\", \"CT\",\n","        \"--dicom-path\", dicom_path,\n","        \"--annotation-path\", annotation_path,\n","        \"--classfile\", \"category.txt\"\n","    ]\n","    \n","    # Execute the command\n","    subprocess.run(command)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"dLqQYoSrW61l"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","4/4 [==============================] - 8s 2s/step - loss: 13.6735 - accuracy: 0.5769 - val_loss: 112.3418 - val_accuracy: 0.4231\n","Epoch 2/20\n","4/4 [==============================] - 6s 1s/step - loss: 12.1742 - accuracy: 0.9423 - val_loss: 177.1836 - val_accuracy: 0.0385\n","Epoch 3/20\n","4/4 [==============================] - 6s 1s/step - loss: 11.8714 - accuracy: 0.9904 - val_loss: 135.1159 - val_accuracy: 0.0385\n","Epoch 4/20\n","4/4 [==============================] - 6s 1s/step - loss: 11.3533 - accuracy: 1.0000 - val_loss: 81.7695 - val_accuracy: 0.3077\n","Epoch 5/20\n","4/4 [==============================] - 8s 2s/step - loss: 10.8409 - accuracy: 1.0000 - val_loss: 57.5599 - val_accuracy: 0.5000\n","Epoch 6/20\n","4/4 [==============================] - 7s 2s/step - loss: 10.2791 - accuracy: 1.0000 - val_loss: 43.7992 - val_accuracy: 0.5000\n","Epoch 7/20\n","4/4 [==============================] - 7s 2s/step - loss: 9.6987 - accuracy: 1.0000 - val_loss: 34.2143 - val_accuracy: 0.5000\n","Epoch 8/20\n","4/4 [==============================] - 7s 2s/step - loss: 9.1187 - accuracy: 1.0000 - val_loss: 26.8619 - val_accuracy: 0.5000\n","Epoch 9/20\n","4/4 [==============================] - 6s 1s/step - loss: 8.5536 - accuracy: 1.0000 - val_loss: 21.3081 - val_accuracy: 0.5769\n","Epoch 10/20\n","4/4 [==============================] - 6s 1s/step - loss: 8.0124 - accuracy: 1.0000 - val_loss: 17.3030 - val_accuracy: 0.6154\n","Epoch 11/20\n","4/4 [==============================] - 6s 1s/step - loss: 7.5005 - accuracy: 1.0000 - val_loss: 14.2518 - val_accuracy: 0.7308\n","Epoch 12/20\n","4/4 [==============================] - 7s 2s/step - loss: 7.0205 - accuracy: 1.0000 - val_loss: 11.9649 - val_accuracy: 0.7308\n","Epoch 13/20\n","4/4 [==============================] - 8s 2s/step - loss: 6.5731 - accuracy: 1.0000 - val_loss: 10.2179 - val_accuracy: 0.7692\n","Epoch 14/20\n","4/4 [==============================] - 6s 2s/step - loss: 6.1581 - accuracy: 1.0000 - val_loss: 8.8643 - val_accuracy: 0.7692\n","Epoch 15/20\n","4/4 [==============================] - 6s 1s/step - loss: 5.7739 - accuracy: 1.0000 - val_loss: 7.7129 - val_accuracy: 0.7692\n","Epoch 16/20\n","4/4 [==============================] - 6s 1s/step - loss: 5.4191 - accuracy: 1.0000 - val_loss: 6.7833 - val_accuracy: 0.8462\n","Epoch 17/20\n","4/4 [==============================] - 6s 1s/step - loss: 5.0915 - accuracy: 1.0000 - val_loss: 6.1313 - val_accuracy: 0.8462\n","Epoch 18/20\n","4/4 [==============================] - 6s 1s/step - loss: 4.7891 - accuracy: 1.0000 - val_loss: 5.6109 - val_accuracy: 0.8462\n","Epoch 19/20\n","4/4 [==============================] - 6s 1s/step - loss: 4.5100 - accuracy: 1.0000 - val_loss: 5.1549 - val_accuracy: 0.8462\n","Epoch 20/20\n","4/4 [==============================] - 6s 1s/step - loss: 4.2520 - accuracy: 1.0000 - val_loss: 4.7785 - val_accuracy: 0.8462\n","Training Accuracy: 1.0\n","Validation Accuracy: 0.8461538553237915\n","Training accuracies:\n","1.0\n"]}],"source":["data = pd.read_csv('output.csv')\n","make_model(data['pixel_data'], data['cancer_type'])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1lr8P0n645eiGh1qg0dLU94-nq-32xY3Q","timestamp":1712890349126}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
